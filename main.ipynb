{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, json, urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "base_list = \"https://www.peakbagger.com/list.aspx?cid=3482&lid=1100\"\n",
    "\n",
    "def real_photo(soup):\n",
    "    for img in soup.find_all(\"img\"):\n",
    "        src = img.get(\"src\", \"\")\n",
    "        if \"pbphoto\" in src:\n",
    "            return urllib.parse.urljoin(base_list, src)\n",
    "    return \"\"\n",
    "\n",
    "html = requests.get(base_list, headers=headers, timeout=30).text\n",
    "table = BeautifulSoup(html, \"html.parser\").find(\"table\", class_=\"gray\")\n",
    "\n",
    "rows = []\n",
    "for tr in table.select(\"tr\"):\n",
    "    tds = tr.find_all(\"td\")\n",
    "    if len(tds) < 4:\n",
    "        continue\n",
    "    rows.append({\n",
    "        \"rank\": int(tds[0].text.strip(\" .\")),\n",
    "        \"country\": tds[1].text.strip(),\n",
    "        \"peak\": tds[2].text.strip(),\n",
    "        \"elev_m\": int(tds[3].text),\n",
    "        \"peak_url\": urllib.parse.urljoin(base_list, tds[2].a[\"href\"])\n",
    "    })\n",
    "\n",
    "for row in rows:\n",
    "    soup = BeautifulSoup(requests.get(row[\"peak_url\"], headers=headers, timeout=30).text, \"html.parser\")\n",
    "    info = soup.find(\"table\", class_=\"gray\")\n",
    "    for tr in info.find_all(\"tr\"):\n",
    "        cells = tr.find_all(\"td\")\n",
    "        if len(cells) < 2:\n",
    "            continue\n",
    "        label = cells[0].get_text(strip=True)\n",
    "        value = cells[1].get_text(\" \", strip=True)\n",
    "        if label.startswith(\"Latitude/Longitude\"):\n",
    "            m = re.match(r\"([-0-9.]+)\\s*,\\s*([-0-9.]+)\", value)\n",
    "            if m:\n",
    "                row[\"lat_dd\"], row[\"lon_dd\"] = map(float, m.groups())\n",
    "        elif label.startswith(\"Prominence\"):\n",
    "            p = re.search(r\"(\\d+)\\s*m\", value)\n",
    "            if p:\n",
    "                row[\"prominence_m\"] = int(p.group(1))\n",
    "        elif label.startswith(\"Isolation\"):\n",
    "            i = re.search(r\"([\\d.]+)\\s*km\", value)\n",
    "            row[\"isolation_km\"] = float(i.group(1)) if i else value.split()[0]\n",
    "    desc_td = soup.find(\"td\", style=re.compile(\"padding:10px\"))\n",
    "    if desc_td:\n",
    "        paras = desc_td.find_all(\"p\")\n",
    "        row[\"description\"] = \" \".join(p.get_text(\" \", strip=True) for p in paras)\n",
    "    else:\n",
    "        row[\"description\"] = \"\"\n",
    "    row[\"photo_url\"] = real_photo(soup)\n",
    "\n",
    "pd.DataFrame(rows).to_json(\"peaks.json\", orient=\"records\", indent=2, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "df = pd.read_json(\"peaks.json\")\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "paths = []\n",
    "for _, row in df.iterrows():\n",
    "    url = row.get(\"photo_url\", \"\")\n",
    "    if url:\n",
    "        parsed = urlparse(url)\n",
    "        name = os.path.basename(parsed.path)\n",
    "        slug = row[\"peak\"].lower().replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "        filename = f\"{slug}_{name}\"\n",
    "        local_path = os.path.join(\"images\", filename)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            with open(local_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            paths.append(local_path)\n",
    "        except:\n",
    "            paths.append(\"\")\n",
    "    else:\n",
    "        paths.append(\"\")\n",
    "\n",
    "df[\"image_path\"] = paths\n",
    "\n",
    "df.to_json(\"peaks_with_images.json\", orient=\"records\", indent=2, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>capital</th>\n",
       "      <th>description</th>\n",
       "      <th>lat_dd</th>\n",
       "      <th>lon_dd</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>Tashkent</td>\n",
       "      <td>capital of Uzbekistan</td>\n",
       "      <td>41.311111</td>\n",
       "      <td>69.279722</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Bern</td>\n",
       "      <td>city in Switzerland, capital of the canton of ...</td>\n",
       "      <td>46.947980</td>\n",
       "      <td>7.447430</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>sovereign island country and city-state in mar...</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>103.800000</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>Skopje</td>\n",
       "      <td>capital city of North Macedonia</td>\n",
       "      <td>41.996111</td>\n",
       "      <td>21.431667</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>federated state, capital and largest city of G...</td>\n",
       "      <td>52.516667</td>\n",
       "      <td>13.383333</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country    capital  \\\n",
       "0       Uzbekistan   Tashkent   \n",
       "1      Switzerland       Bern   \n",
       "2        Singapore  Singapore   \n",
       "3  North Macedonia     Skopje   \n",
       "4          Germany     Berlin   \n",
       "\n",
       "                                         description     lat_dd      lon_dd  \\\n",
       "0                              capital of Uzbekistan  41.311111   69.279722   \n",
       "1  city in Switzerland, capital of the canton of ...  46.947980    7.447430   \n",
       "2  sovereign island country and city-state in mar...   1.300000  103.800000   \n",
       "3                    capital city of North Macedonia  41.996111   21.431667   \n",
       "4  federated state, capital and largest city of G...  52.516667   13.383333   \n",
       "\n",
       "                                           image_url  \n",
       "0  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "1  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "2  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "3  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "4  http://commons.wikimedia.org/wiki/Special:File...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT ?countryLabel ?capitalLabel ?coord ?desc ?image WHERE {\n",
    "  ?country wdt:P31 wd:Q3624078; wdt:P36 ?capital.\n",
    "  ?capital wdt:P625 ?coord.\n",
    "  OPTIONAL { ?capital schema:description ?desc FILTER(LANG(?desc)=\"en\") }\n",
    "  OPTIONAL { ?capital wdt:P18 ?image         }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n",
    "}\n",
    "\"\"\"\n",
    "r = requests.get(\"https://query.wikidata.org/sparql\", params={\"format\":\"json\",\"query\":q})\n",
    "rows = []\n",
    "for b in r.json()[\"results\"][\"bindings\"]:\n",
    "    lon, lat = b[\"coord\"][\"value\"].removeprefix(\"Point(\").removesuffix(\")\").split(\" \")\n",
    "    rows.append({\n",
    "        \"country\":      b[\"countryLabel\"][\"value\"],\n",
    "        \"capital\":      b[\"capitalLabel\"][\"value\"],\n",
    "        \"description\":  b.get(\"desc\",{}).get(\"value\",\"\"),\n",
    "        \"lat_dd\":       float(lat),\n",
    "        \"lon_dd\":       float(lon),\n",
    "        \"image_url\":    b.get(\"image\",{}).get(\"value\",\"\")\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_json(\"capitals.json\", orient=\"records\", indent=2, force_ascii=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "df = pd.read_json(\"capitals.json\")\n",
    "\n",
    "os.makedirs(\"capital_images\", exist_ok=True)\n",
    "\n",
    "paths = []\n",
    "for _, row in df.iterrows():\n",
    "    url = row.get(\"image_url\",\"\")\n",
    "    if url:\n",
    "        p = urlparse(url)\n",
    "        ext = os.path.splitext(p.path)[1] or \".jpg\"\n",
    "        slug = row[\"capital\"].lower().replace(\" \",\"_\").replace(\"/\",\"_\")\n",
    "        fname = f\"{slug}{ext}\"\n",
    "        local = os.path.join(\"capital_images\", fname)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            with open(local, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            paths.append(local)\n",
    "        except:\n",
    "            paths.append(\"\")\n",
    "    else:\n",
    "        paths.append(\"\")\n",
    "\n",
    "df[\"image_path\"] = paths\n",
    "\n",
    "df.to_json(\"capitals_with_images.json\", orient=\"records\", indent=2, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests, zipfile, io\n",
    "from math import radians, sin, cos, atan2\n",
    "\n",
    "peaks = pd.read_json(\"peaks_with_images.json\")\n",
    "caps  = pd.read_json(\"capitals_with_images.json\")\n",
    "\n",
    "def hav(lat1, lon1, lat2, lon2):\n",
    "    R=6371\n",
    "    dlat=radians(lat2-lat1)\n",
    "    dlon=radians(lon2-lon1)\n",
    "    a=sin(dlat/2)**2 + cos(radians(lat1))*cos(radians(lat2))*sin(dlon/2)**2\n",
    "    return R*2*atan2(a**0.5,(1-a)**0.5)\n",
    "\n",
    "df = peaks.merge(caps, on=\"country\", suffixes=(\"_pk\",\"_cp\"))\n",
    "df[\"dist_km\"] = df.apply(lambda r: hav(r.lat_dd_pk, r.lon_dd_pk, r.lat_dd_cp, r.lon_dd_cp), axis=1)\n",
    "\n",
    "r = requests.get(\"https://naturalearth.s3.amazonaws.com/10m_cultural/ne_10m_admin_0_map_subunits.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(\"ne_subunits\")\n",
    "sub = gpd.read_file(\"ne_subunits/ne_10m_admin_0_map_subunits.shp\")\n",
    "cn = sub.dissolve(by=\"ADMIN\").reset_index()[[\"ADMIN\",\"geometry\"]].rename(columns={\"ADMIN\":\"country\"})\n",
    "gdf = cn.merge(df, on=\"country\").to_crs(epsg=3857)\n",
    "\n",
    "def get_coords(p):\n",
    "    if p.geom_type==\"Polygon\":\n",
    "        x,y = p.exterior.coords.xy\n",
    "        return list(x), list(y)\n",
    "    xs, ys = [], []\n",
    "    for part in p.geoms:\n",
    "        x,y = part.exterior.coords.xy\n",
    "        xs += list(x)+[None]\n",
    "        ys += list(y)+[None]\n",
    "    return xs, ys\n",
    "\n",
    "gdf[\"xs\"], gdf[\"ys\"] = zip(*gdf.geometry.apply(get_coords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "country_map = {\n",
    "  \"Falkland Islands\": \"United Kingdom\",\n",
    "  \"South Georgia and the Islands\": \"United Kingdom\",\n",
    "  \"South Georgia\": \"United Kingdom\",\n",
    "  \"Anguilla\": \"United Kingdom\",\n",
    "  \"Bermuda\": \"United Kingdom\",\n",
    "  \"British Indian Ocean Territory\": \"United Kingdom\",\n",
    "  \"British Virgin Islands\": \"United Kingdom\",\n",
    "  \"Gibraltar\": \"United Kingdom\",\n",
    "  \"Guernsey\": \"United Kingdom\",\n",
    "  \"Isle of Man\": \"United Kingdom\",\n",
    "  \"Jersey\": \"United Kingdom\",\n",
    "  \"Montserrat\": \"United Kingdom\",\n",
    "  \"Pitcairn Islands\": \"United Kingdom\",\n",
    "  \"Pitcairn Island\": \"United Kingdom\",\n",
    "  \"Saint Helena\": \"United Kingdom\",\n",
    "  \"Ascension Island\": \"United Kingdom\",\n",
    "  \"Turks and Caicos Islands\": \"United Kingdom\",\n",
    "  \"United States\": \"United States of America\",\n",
    "  \"United States Virgin Islands\": \"United States of America\",\n",
    "  \"United States Minor Outlying Islands\": \"United States of America\",\n",
    "  \"U.S. Minor Pacific Islands\": \"United States of America\",\n",
    "  \"Navassa\": \"United States of America\",\n",
    "  \"Northern Mariana Islands\": \"United States of America\",\n",
    "  \"Puerto Rico\": \"United States of America\",\n",
    "  \"American Samoa\": \"United States of America\",\n",
    "  \"French Polynesia\": \"France\",\n",
    "  \"French Southern and Antarctic Lands\": \"France\",\n",
    "  \"French Southern Territories\": \"France\",\n",
    "  \"Reunion\": \"France\",\n",
    "  \"Guadeloupe\": \"France\",\n",
    "  \"Martinique\": \"France\",\n",
    "  \"Mayotte\": \"France\",\n",
    "  \"New Caledonia\": \"France\",\n",
    "  \"French Guiana\": \"France\",\n",
    "  \"Wallis and Futuna\": \"France\",\n",
    "  \"Saint Pierre and Miquelon\": \"France\",\n",
    "  \"Curaçao\": \"Netherlands\",\n",
    "  \"Aruba\": \"Netherlands\",\n",
    "  \"Sint Maarten\": \"Netherlands\",\n",
    "  \"Bonaire\": \"Netherlands\",\n",
    "  \"Saba\": \"Netherlands\",\n",
    "  \"Sint Eustatius\": \"Netherlands\",\n",
    "  \"Kingdom of the Netherlands\": \"Netherlands\",\n",
    "  \"Greenland\": \"Denmark\",\n",
    "  \"Faroe Islands\": \"Denmark\",\n",
    "  \"Kingdom of Denmark\": \"Denmark\",\n",
    "  \"Christmas Island\": \"Australia\",\n",
    "  \"Cocos Islands\": \"Australia\",\n",
    "  \"Indian Ocean Territories\": \"Australia\",\n",
    "  \"Ashmore and Cartier Islands\": \"Australia\",\n",
    "  \"Heard and McDonald Islands\": \"Australia\",\n",
    "  \"Coral Sea Islands\": \"Australia\",\n",
    "  \"Coral Sea Islands Territory\": \"Australia\",\n",
    "  \"People's Republic of China\": \"China\",\n",
    "  \"PRC\": \"China\",\n",
    "  \"Hong Kong S.A.R.\": \"China\",\n",
    "  \"Hong Kong\": \"China\",\n",
    "  \"Macao S.A.R\": \"China\",\n",
    "  \"Macau\": \"China\",\n",
    "  \"Czech Republic\": \"Czechia\",\n",
    "  \"Cape Verde\": \"Cabo Verde\",\n",
    "  \"Congo DRC\": \"Democratic Republic of the Congo\",\n",
    "  \"Democratic Republic of the Congo\": \"Democratic Republic of the Congo\",\n",
    "  \"Congo Republic\": \"Republic of the Congo\",\n",
    "  \"Eswatini\": \"eSwatini\",\n",
    "  \"Bahamas\": \"Bahamas\",\n",
    "  \"The Bahamas\": \"Bahamas\",\n",
    "  \"Gambia\": \"Gambia\",\n",
    "  \"The Gambia\": \"Gambia\",\n",
    "  \"Palestinian Authority\": \"Palestine\",\n",
    "  \"State of Palestine\": \"Palestine\",\n",
    "  \"Sixth Republic of South Korea\": \"South Korea\",\n",
    "  \"Republic of Serbia\": \"Serbia\",\n",
    "  \"Sao Tome and Principe\": \"São Tomé and Príncipe\",\n",
    "  \"Ivory Coast\": \"Ivory Coast\",\n",
    "  \"Côte d'Ivoire\": \"Ivory Coast\",\n",
    "  \"Fiji Islands\": \"Fiji\",\n",
    "  \"Portuguese Republic\": \"Portugal\",\n",
    "  \"Republic of Portugal\": \"Portugal\",\n",
    "  \"Republic of Poland\": \"Poland\",\n",
    "  \"Polish Republic\": \"Poland\",\n",
    "  \"United Republic of Tanzania\": \"Tanzania\",\n",
    "  \"Somaliland\": \"Somalia\",\n",
    "  \"East Timor\": \"Timor Leste\",\n",
    "  \"Timor-Leste\": \"Timor Leste\",\n",
    "  \"Jan Mayen\": \"Norway\",\n",
    "  \"Bouvet Island\": \"Norway\",\n",
    "  \"Svalbard\": \"Norway\",\n",
    "  \"Tristan da Cunha\": \"United Kingdom\",\n",
    "  \"Tokelau\": \"New Zealand\",\n",
    "  \"Cook Islands\": \"Cook Islands\",\n",
    "  \"American Samoa\": \"United States of America\",\n",
    "  \"Bouvet Island\": \"Norway\",\n",
    "  \"Cayman Islands\": \"United Kingdom\",\n",
    "  \"Cook Islands\": \"New Zealand\",\n",
    "  \"East Timor\": \"Timor Leste\",\n",
    "  \"French Southern Lands\": \"France\",\n",
    "  \"Guam\": \"United States of America\",\n",
    "  \"Jan Mayen\": \"Norway\",\n",
    "  \"Micronesia\": \"Federated States of Micronesia\",\n",
    "  \"Niue\": \"New Zealand\",\n",
    "  \"Norfolk Island\": \"Australia\",\n",
    "  \"Northern Marianas\": \"United States of America\",\n",
    "  \"Pitcairn Island\": \"United Kingdom\",\n",
    "  \"Puerto Rico\": \"United States of America\",\n",
    "  \"Saint Barthelemy\": \"France\",\n",
    "  \"Saint Helena, Ascension, Tristan da Cunha\": \"United Kingdom\",\n",
    "  \"Saint Martin\": \"France\",\n",
    "  \"Svalbard\": \"Norway\",\n",
    "  \"Tokelau\": \"New Zealand\",\n",
    "  \"U.S. Virgin Islands\": \"United States of America\",\n",
    "  \"Vatican City\": \"Vatican\",\n",
    "  \"Kingdom of Lesotho\": \"Lesotho\",\n",
    "  \"Heard Island and McDonald Islands\": \"Australia\"\n",
    "}\n",
    "\n",
    "with open(\"country_map.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(country_map, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json\n",
    "\n",
    "caps = pd.read_json(\"caps_clean.json\")\n",
    "\n",
    "with open(\"country_map.json\") as f:\n",
    "    cmap = json.load(f)\n",
    "cmap.setdefault(\"Kosovo\", \"Kosovo\")\n",
    "with open(\"country_map.json\",\"w\") as f:\n",
    "    json.dump(cmap,f,indent=2)\n",
    "\n",
    "if \"Kosovo\" not in caps.country.values:\n",
    "    caps.loc[len(caps)] = {\n",
    "        \"country\":    \"Kosovo\",\n",
    "        \"capital\":    \"Pristina\",\n",
    "        \"lat_dd\":     42.6629,\n",
    "        \"lon_dd\":     21.1655,\n",
    "        \"description\":\"Capital of Kosovo\",\n",
    "        \"photo_url\":  None\n",
    "    }\n",
    "    caps.to_json(\"caps_clean.json\", orient=\"records\", indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 countries by distance:\n",
      "United Kingdom: 12255 km (Mount Paget→London)\n",
      "Netherlands: 6985 km (Mount Scenery→Amsterdam)\n",
      "Australia: 6036 km (Big Ben→Canberra)\n",
      "United States of America: 5439 km (Denali→Washington, D.C.)\n",
      "Canada: 4431 km (Mount Logan→Ottawa)\n",
      "\n",
      "Shortest distance:\n",
      "San Marino: 0 km (Monte Titano→San Marino)\n"
     ]
    }
   ],
   "source": [
    "top5 = (\n",
    "    dist\n",
    "    .nlargest(5, 'dist_km')\n",
    "    [['country', 'capital', 'peak', 'dist_km']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "min1 = (\n",
    "    dist\n",
    "    .nsmallest(1, 'dist_km')\n",
    "    [['country', 'capital', 'peak', 'dist_km']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "lines_top = [\n",
    "    f\"{row.country}: {row.dist_km:.0f} km ({row.peak}→{row.capital})\"\n",
    "    for row in top5.itertuples()\n",
    "]\n",
    "lines_min = [\n",
    "    f\"{row.country}: {row.dist_km:.0f} km ({row.peak}→{row.capital})\"\n",
    "    for row in min1.itertuples()\n",
    "]\n",
    "\n",
    "annotation = (\n",
    "    \"Top 5 countries by distance:\\n\" +\n",
    "    \"\\n\".join(lines_top) +\n",
    "    \"\\n\\nShortest distance:\\n\" +\n",
    "    \"\\n\".join(lines_min)\n",
    ")\n",
    "\n",
    "print(annotation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/mat/Documents/peak_capital_map/peak_capital_distance.html'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from bokeh.io import output_file, save\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, Div\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Blues256\n",
    "\n",
    "palette = (Blues256[::-1][15:], \"white\", \"#005285\", \"#7dbaff\", \"gray\")\n",
    "show_peaks, show_caps = True, True\n",
    "map_palette, back_color, peak_color, cap_color, text_color = palette\n",
    "K, MID = 0.0008, 1500\n",
    "\n",
    "with open(\"country_map.json\") as f:\n",
    "    cmap = json.load(f)\n",
    "unify = lambda n: cmap.get(n, n)\n",
    "\n",
    "peaks = pd.read_json(\"peaks_with_images.json\")\n",
    "caps  = pd.read_json(\"caps_clean.json\")\n",
    "sub   = gpd.read_file(\"ne_subunits/ne_10m_admin_0_map_subunits.shp\")\n",
    "\n",
    "peaks[\"country\"] = peaks[\"country\"].apply(unify)\n",
    "caps[\"country\"]  = caps[\"country\"].apply(unify)\n",
    "sub = sub[sub.ADMIN != \"Antarctica\"].assign(country=sub.ADMIN.apply(unify))\n",
    "\n",
    "peaks = peaks[peaks.lat_dd > -60]\n",
    "peaks = peaks.assign(country=peaks.country.str.split(\"/\")).explode(\"country\")\n",
    "peaks = peaks.loc[peaks.groupby(\"country\")[\"elev_m\"].idxmax()].reset_index(drop=True)\n",
    "\n",
    "def hav(a, b, c, d):\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = np.radians([a, b, c, d])\n",
    "    dlat, dlon = lat2 - lat1, lon2 - lon1\n",
    "    h = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    return R * 2 * np.arctan2(np.sqrt(h), np.sqrt(1 - h))\n",
    "\n",
    "dist = peaks.merge(caps, on=\"country\", suffixes=(\"_pk\", \"_cp\"))\n",
    "dist[\"dist_km\"] = hav(dist.lat_dd_pk, dist.lon_dd_pk, dist.lat_dd_cp, dist.lon_dd_cp)\n",
    "\n",
    "cn = sub.dissolve(by=\"country\").reset_index()\n",
    "cn = cn.merge(dist[[\"country\", \"dist_km\", \"peak\", \"capital\", \"elev_m\"]], on=\"country\", how=\"left\").explode(ignore_index=True)\n",
    "\n",
    "crs_proj = \"+proj=robin +lon_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "cn = cn.to_crs(crs_proj)\n",
    "\n",
    "def get_coords(poly):\n",
    "    x, y = poly.exterior.coords.xy\n",
    "    return list(x), list(y)\n",
    "\n",
    "cn[\"xs\"], cn[\"ys\"] = zip(*cn.geometry.apply(get_coords))\n",
    "cn = cn.drop(columns=\"geometry\")\n",
    "\n",
    "peaks = gpd.GeoDataFrame(peaks, geometry=gpd.points_from_xy(peaks.lon_dd, peaks.lat_dd), crs=\"EPSG:4326\").to_crs(crs_proj)\n",
    "peaks[\"x\"], peaks[\"y\"] = peaks.geometry.x, peaks.geometry.y\n",
    "peaks = peaks.drop(columns=\"geometry\")\n",
    "\n",
    "caps = gpd.GeoDataFrame(caps, geometry=gpd.points_from_xy(caps.lon_dd, caps.lat_dd), crs=\"EPSG:4326\").to_crs(crs_proj)\n",
    "caps[\"x\"], caps[\"y\"] = caps.geometry.x, caps.geometry.y\n",
    "caps = caps.drop(columns=\"geometry\")\n",
    "\n",
    "cn[\"dist_color\"] = 1 / (1 + np.exp(-K * ((cn[\"dist_km\"] + 100) - MID)))\n",
    "\n",
    "gsrc   = ColumnDataSource(cn)\n",
    "mapper = LinearColorMapper(palette=map_palette, low=cn.dist_color.min(), high=cn.dist_color.max())\n",
    "\n",
    "xs_all = np.hstack(cn[\"xs\"].to_list())\n",
    "ys_all = np.hstack(cn[\"ys\"].to_list())\n",
    "pad_x  = 0.001 * (xs_all.max() - xs_all.min())\n",
    "pad_y  = 0.001 * (ys_all.max() - ys_all.min())\n",
    "x_rng  = (xs_all.min() + pad_x, xs_all.max() - pad_x)\n",
    "y_rng  = (ys_all.min() + pad_y, ys_all.max() - pad_y)\n",
    "\n",
    "p = figure(\n",
    "    x_range=x_rng,\n",
    "    y_range=y_rng,\n",
    "    match_aspect=True,\n",
    "    sizing_mode=\"stretch_both\",\n",
    "    tools=\"pan,wheel_zoom,reset\",\n",
    "    active_scroll=\"wheel_zoom\",\n",
    "    toolbar_location=None,\n",
    "    background_fill_color=back_color,\n",
    "    border_fill_color=back_color,\n",
    "    min_border=0,\n",
    ")\n",
    "\n",
    "p.outline_line_color = None\n",
    "p.axis.visible       = False\n",
    "p.grid.grid_line_color = None\n",
    "\n",
    "p.title.text            = \"Distance from Highest Peak to Capital\"\n",
    "p.title.align           = \"center\"\n",
    "p.title.text_font_size  = \"30pt\"\n",
    "p.title.text_font_style = \"normal\"\n",
    "p.title.text_color      = \"gray\"\n",
    "p.min_border_top        = 50\n",
    "\n",
    "p.patches(\n",
    "    \"xs\", \"ys\", source=gsrc,\n",
    "    fill_color={\"field\": \"dist_color\", \"transform\": mapper},\n",
    "    line_color=None, line_width=0,\n",
    ")\n",
    "\n",
    "if show_peaks:\n",
    "    p.scatter(\"x\", \"y\", source=ColumnDataSource(peaks),\n",
    "              marker=\"triangle\", size=6,\n",
    "              fill_color=peak_color, line_color=peak_color,\n",
    "              legend_label=\"Highest peak\")\n",
    "\n",
    "if show_caps:\n",
    "    p.scatter(\"x\", \"y\", source=ColumnDataSource(caps),\n",
    "              marker=\"star\", size=6,\n",
    "              fill_color=cap_color, line_color=cap_color,\n",
    "              legend_label=\"Capital city\")\n",
    "\n",
    "tooltip = \"\"\"\n",
    "<div>\n",
    "  <style>\n",
    "    :host{background:transparent!important;border:1px solid #fff!important;border-radius:8px!important;box-shadow:none!important;padding:0!important;}\n",
    "    .bk-tooltip-arrow{display:none!important;}\n",
    "    .inner-box{background-color:#222;color:#eee;padding:6px;border-radius:8px;display:flex;flex-direction:column;gap:4px;}\n",
    "  </style>\n",
    "  <div class=\"inner-box\">\n",
    "    <div style=\"display:flex;gap:10px;\"><span style=\"font-weight:bold;\">@country</span><span>@capital</span><span>@peak</span></div>\n",
    "    <div style=\"display:flex;gap:10px;\"><span>Elevation&nbsp;@elev_m&nbsp;m</span><span>Distance&nbsp;@dist_km{0.0}&nbsp;km</span></div>\n",
    "  </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "p.add_tools(HoverTool(renderers=[p.renderers[0]], tooltips=tooltip,\n",
    "                      point_policy=\"follow_mouse\", show_arrow=False))\n",
    "\n",
    "p.legend.location              = \"bottom_left\"\n",
    "p.legend.background_fill_alpha = 0.0\n",
    "p.legend.label_text_color      = text_color\n",
    "p.legend.label_text_font_size  = \"10pt\"\n",
    "p.legend.border_line_color     = None\n",
    "\n",
    "credit_div = Div(\n",
    "    text=\"\"\"\n",
    "    <div style='text-align:right; font-size:10pt; color:#555; width:100%;'>\n",
    "      Data: <a href='https://www.peakbagger.com' target='_blank'>Peakbagger</a> |\n",
    "      <a href='https://www.wikipedia.org' target='_blank'>Wikipedia</a> |\n",
    "      <a href='https://www.naturalearthdata.com' target='_blank'>Natural&nbsp;Earth</a>\n",
    "      &nbsp;&bull;&nbsp; Map framework: <a href='https://bokeh.org' target='_blank'>Bokeh</a> |\n",
    "      Source code: <a href='https://github.com/jan-mate/peak_capital_distance' target='_blank'>GitHub</a>\n",
    "    </div>\n",
    "    \"\"\",\n",
    "    sizing_mode=\"stretch_width\",\n",
    "    margin=(0, 10, 10, 0)  # top, right, bottom, left\n",
    ")\n",
    "\n",
    "layout = column(p, credit_div, sizing_mode=\"stretch_both\")\n",
    "\n",
    "output_file(\"peak_capital_distance.html\",\n",
    "            title=\"Peak–Capital Distance Map\")\n",
    "\n",
    "save(layout)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
