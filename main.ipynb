{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re, json, urllib.parse\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "base_list = \"https://www.peakbagger.com/list.aspx?cid=3482&lid=1100\"\n",
    "\n",
    "def real_photo(soup):\n",
    "    for img in soup.find_all(\"img\"):\n",
    "        src = img.get(\"src\", \"\")\n",
    "        if \"pbphoto\" in src:\n",
    "            return urllib.parse.urljoin(base_list, src)\n",
    "    return \"\"\n",
    "\n",
    "html = requests.get(base_list, headers=headers, timeout=30).text\n",
    "table = BeautifulSoup(html, \"html.parser\").find(\"table\", class_=\"gray\")\n",
    "\n",
    "rows = []\n",
    "for tr in table.select(\"tr\"):\n",
    "    tds = tr.find_all(\"td\")\n",
    "    if len(tds) < 4:\n",
    "        continue\n",
    "    rows.append({\n",
    "        \"rank\": int(tds[0].text.strip(\" .\")),\n",
    "        \"country\": tds[1].text.strip(),\n",
    "        \"peak\": tds[2].text.strip(),\n",
    "        \"elev_m\": int(tds[3].text),\n",
    "        \"peak_url\": urllib.parse.urljoin(base_list, tds[2].a[\"href\"])\n",
    "    })\n",
    "\n",
    "for row in rows:\n",
    "    soup = BeautifulSoup(requests.get(row[\"peak_url\"], headers=headers, timeout=30).text, \"html.parser\")\n",
    "    info = soup.find(\"table\", class_=\"gray\")\n",
    "    for tr in info.find_all(\"tr\"):\n",
    "        cells = tr.find_all(\"td\")\n",
    "        if len(cells) < 2:\n",
    "            continue\n",
    "        label = cells[0].get_text(strip=True)\n",
    "        value = cells[1].get_text(\" \", strip=True)\n",
    "        if label.startswith(\"Latitude/Longitude\"):\n",
    "            m = re.match(r\"([-0-9.]+)\\s*,\\s*([-0-9.]+)\", value)\n",
    "            if m:\n",
    "                row[\"lat_dd\"], row[\"lon_dd\"] = map(float, m.groups())\n",
    "        elif label.startswith(\"Prominence\"):\n",
    "            p = re.search(r\"(\\d+)\\s*m\", value)\n",
    "            if p:\n",
    "                row[\"prominence_m\"] = int(p.group(1))\n",
    "        elif label.startswith(\"Isolation\"):\n",
    "            i = re.search(r\"([\\d.]+)\\s*km\", value)\n",
    "            row[\"isolation_km\"] = float(i.group(1)) if i else value.split()[0]\n",
    "    desc_td = soup.find(\"td\", style=re.compile(\"padding:10px\"))\n",
    "    if desc_td:\n",
    "        paras = desc_td.find_all(\"p\")\n",
    "        row[\"description\"] = \" \".join(p.get_text(\" \", strip=True) for p in paras)\n",
    "    else:\n",
    "        row[\"description\"] = \"\"\n",
    "    row[\"photo_url\"] = real_photo(soup)\n",
    "\n",
    "pd.DataFrame(rows).to_json(\"peaks.json\", orient=\"records\", indent=2, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "df = pd.read_json(\"peaks.json\")\n",
    "\n",
    "os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "paths = []\n",
    "for _, row in df.iterrows():\n",
    "    url = row.get(\"photo_url\", \"\")\n",
    "    if url:\n",
    "        parsed = urlparse(url)\n",
    "        name = os.path.basename(parsed.path)\n",
    "        slug = row[\"peak\"].lower().replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "        filename = f\"{slug}_{name}\"\n",
    "        local_path = os.path.join(\"images\", filename)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            with open(local_path, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            paths.append(local_path)\n",
    "        except:\n",
    "            paths.append(\"\")\n",
    "    else:\n",
    "        paths.append(\"\")\n",
    "\n",
    "df[\"image_path\"] = paths\n",
    "\n",
    "df.to_json(\"peaks_with_images.json\", orient=\"records\", indent=2, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capitals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>capital</th>\n",
       "      <th>description</th>\n",
       "      <th>lat_dd</th>\n",
       "      <th>lon_dd</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Uzbekistan</td>\n",
       "      <td>Tashkent</td>\n",
       "      <td>capital of Uzbekistan</td>\n",
       "      <td>41.311111</td>\n",
       "      <td>69.279722</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Bern</td>\n",
       "      <td>city in Switzerland, capital of the canton of ...</td>\n",
       "      <td>46.947980</td>\n",
       "      <td>7.447430</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Singapore</td>\n",
       "      <td>Singapore</td>\n",
       "      <td>sovereign island country and city-state in mar...</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>103.800000</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>North Macedonia</td>\n",
       "      <td>Skopje</td>\n",
       "      <td>capital city of North Macedonia</td>\n",
       "      <td>41.996111</td>\n",
       "      <td>21.431667</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>federated state, capital and largest city of G...</td>\n",
       "      <td>52.516667</td>\n",
       "      <td>13.383333</td>\n",
       "      <td>http://commons.wikimedia.org/wiki/Special:File...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           country    capital  \\\n",
       "0       Uzbekistan   Tashkent   \n",
       "1      Switzerland       Bern   \n",
       "2        Singapore  Singapore   \n",
       "3  North Macedonia     Skopje   \n",
       "4          Germany     Berlin   \n",
       "\n",
       "                                         description     lat_dd      lon_dd  \\\n",
       "0                              capital of Uzbekistan  41.311111   69.279722   \n",
       "1  city in Switzerland, capital of the canton of ...  46.947980    7.447430   \n",
       "2  sovereign island country and city-state in mar...   1.300000  103.800000   \n",
       "3                    capital city of North Macedonia  41.996111   21.431667   \n",
       "4  federated state, capital and largest city of G...  52.516667   13.383333   \n",
       "\n",
       "                                           image_url  \n",
       "0  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "1  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "2  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "3  http://commons.wikimedia.org/wiki/Special:File...  \n",
       "4  http://commons.wikimedia.org/wiki/Special:File...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "q = \"\"\"\n",
    "SELECT ?countryLabel ?capitalLabel ?coord ?desc ?image WHERE {\n",
    "  ?country wdt:P31 wd:Q3624078; wdt:P36 ?capital.\n",
    "  ?capital wdt:P625 ?coord.\n",
    "  OPTIONAL { ?capital schema:description ?desc FILTER(LANG(?desc)=\"en\") }\n",
    "  OPTIONAL { ?capital wdt:P18 ?image         }\n",
    "  SERVICE wikibase:label { bd:serviceParam wikibase:language \"en\" }\n",
    "}\n",
    "\"\"\"\n",
    "r = requests.get(\"https://query.wikidata.org/sparql\", params={\"format\":\"json\",\"query\":q})\n",
    "rows = []\n",
    "for b in r.json()[\"results\"][\"bindings\"]:\n",
    "    lon, lat = b[\"coord\"][\"value\"].removeprefix(\"Point(\").removesuffix(\")\").split(\" \")\n",
    "    rows.append({\n",
    "        \"country\":      b[\"countryLabel\"][\"value\"],\n",
    "        \"capital\":      b[\"capitalLabel\"][\"value\"],\n",
    "        \"description\":  b.get(\"desc\",{}).get(\"value\",\"\"),\n",
    "        \"lat_dd\":       float(lat),\n",
    "        \"lon_dd\":       float(lon),\n",
    "        \"image_url\":    b.get(\"image\",{}).get(\"value\",\"\")\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_json(\"capitals.json\", orient=\"records\", indent=2, force_ascii=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "df = pd.read_json(\"capitals.json\")\n",
    "\n",
    "os.makedirs(\"capital_images\", exist_ok=True)\n",
    "\n",
    "paths = []\n",
    "for _, row in df.iterrows():\n",
    "    url = row.get(\"image_url\",\"\")\n",
    "    if url:\n",
    "        p = urlparse(url)\n",
    "        ext = os.path.splitext(p.path)[1] or \".jpg\"\n",
    "        slug = row[\"capital\"].lower().replace(\" \",\"_\").replace(\"/\",\"_\")\n",
    "        fname = f\"{slug}{ext}\"\n",
    "        local = os.path.join(\"capital_images\", fname)\n",
    "        try:\n",
    "            r = requests.get(url, timeout=10)\n",
    "            r.raise_for_status()\n",
    "            with open(local, \"wb\") as f:\n",
    "                f.write(r.content)\n",
    "            paths.append(local)\n",
    "        except:\n",
    "            paths.append(\"\")\n",
    "    else:\n",
    "        paths.append(\"\")\n",
    "\n",
    "df[\"image_path\"] = paths\n",
    "\n",
    "df.to_json(\"capitals_with_images.json\", orient=\"records\", indent=2, force_ascii=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests, zipfile, io\n",
    "from math import radians, sin, cos, atan2\n",
    "\n",
    "peaks = pd.read_json(\"peaks_with_images.json\")\n",
    "caps  = pd.read_json(\"capitals_with_images.json\")\n",
    "\n",
    "def hav(lat1, lon1, lat2, lon2):\n",
    "    R=6371\n",
    "    dlat=radians(lat2-lat1)\n",
    "    dlon=radians(lon2-lon1)\n",
    "    a=sin(dlat/2)**2 + cos(radians(lat1))*cos(radians(lat2))*sin(dlon/2)**2\n",
    "    return R*2*atan2(a**0.5,(1-a)**0.5)\n",
    "\n",
    "df = peaks.merge(caps, on=\"country\", suffixes=(\"_pk\",\"_cp\"))\n",
    "df[\"dist_km\"] = df.apply(lambda r: hav(r.lat_dd_pk, r.lon_dd_pk, r.lat_dd_cp, r.lon_dd_cp), axis=1)\n",
    "\n",
    "r = requests.get(\"https://naturalearth.s3.amazonaws.com/10m_cultural/ne_10m_admin_0_map_subunits.zip\")\n",
    "z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "z.extractall(\"ne_subunits\")\n",
    "sub = gpd.read_file(\"ne_subunits/ne_10m_admin_0_map_subunits.shp\")\n",
    "cn = sub.dissolve(by=\"ADMIN\").reset_index()[[\"ADMIN\",\"geometry\"]].rename(columns={\"ADMIN\":\"country\"})\n",
    "gdf = cn.merge(df, on=\"country\").to_crs(epsg=3857)\n",
    "\n",
    "def get_coords(p):\n",
    "    if p.geom_type==\"Polygon\":\n",
    "        x,y = p.exterior.coords.xy\n",
    "        return list(x), list(y)\n",
    "    xs, ys = [], []\n",
    "    for part in p.geoms:\n",
    "        x,y = part.exterior.coords.xy\n",
    "        xs += list(x)+[None]\n",
    "        ys += list(y)+[None]\n",
    "    return xs, ys\n",
    "\n",
    "gdf[\"xs\"], gdf[\"ys\"] = zip(*gdf.geometry.apply(get_coords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "country_map = {\n",
    "  \"Falkland Islands\": \"United Kingdom\",\n",
    "  \"South Georgia and the Islands\": \"United Kingdom\",\n",
    "  \"South Georgia\": \"United Kingdom\",\n",
    "  \"Anguilla\": \"United Kingdom\",\n",
    "  \"Bermuda\": \"United Kingdom\",\n",
    "  \"British Indian Ocean Territory\": \"United Kingdom\",\n",
    "  \"British Virgin Islands\": \"United Kingdom\",\n",
    "  \"Gibraltar\": \"United Kingdom\",\n",
    "  \"Guernsey\": \"United Kingdom\",\n",
    "  \"Isle of Man\": \"United Kingdom\",\n",
    "  \"Jersey\": \"United Kingdom\",\n",
    "  \"Montserrat\": \"United Kingdom\",\n",
    "  \"Pitcairn Islands\": \"United Kingdom\",\n",
    "  \"Pitcairn Island\": \"United Kingdom\",\n",
    "  \"Saint Helena\": \"United Kingdom\",\n",
    "  \"Ascension Island\": \"United Kingdom\",\n",
    "  \"Turks and Caicos Islands\": \"United Kingdom\",\n",
    "  \"United States\": \"United States of America\",\n",
    "  \"United States Virgin Islands\": \"United States of America\",\n",
    "  \"United States Minor Outlying Islands\": \"United States of America\",\n",
    "  \"U.S. Minor Pacific Islands\": \"United States of America\",\n",
    "  \"Navassa\": \"United States of America\",\n",
    "  \"Northern Mariana Islands\": \"United States of America\",\n",
    "  \"Puerto Rico\": \"United States of America\",\n",
    "  \"American Samoa\": \"United States of America\",\n",
    "  \"French Polynesia\": \"France\",\n",
    "  \"French Southern and Antarctic Lands\": \"France\",\n",
    "  \"French Southern Territories\": \"France\",\n",
    "  \"Reunion\": \"France\",\n",
    "  \"Guadeloupe\": \"France\",\n",
    "  \"Martinique\": \"France\",\n",
    "  \"Mayotte\": \"France\",\n",
    "  \"New Caledonia\": \"France\",\n",
    "  \"French Guiana\": \"France\",\n",
    "  \"Wallis and Futuna\": \"France\",\n",
    "  \"Saint Pierre and Miquelon\": \"France\",\n",
    "  \"Curaçao\": \"Netherlands\",\n",
    "  \"Aruba\": \"Netherlands\",\n",
    "  \"Sint Maarten\": \"Netherlands\",\n",
    "  \"Bonaire\": \"Netherlands\",\n",
    "  \"Saba\": \"Netherlands\",\n",
    "  \"Sint Eustatius\": \"Netherlands\",\n",
    "  \"Kingdom of the Netherlands\": \"Netherlands\",\n",
    "  \"Greenland\": \"Denmark\",\n",
    "  \"Faroe Islands\": \"Denmark\",\n",
    "  \"Kingdom of Denmark\": \"Denmark\",\n",
    "  \"Christmas Island\": \"Australia\",\n",
    "  \"Cocos Islands\": \"Australia\",\n",
    "  \"Indian Ocean Territories\": \"Australia\",\n",
    "  \"Ashmore and Cartier Islands\": \"Australia\",\n",
    "  \"Heard and McDonald Islands\": \"Australia\",\n",
    "  \"Coral Sea Islands\": \"Australia\",\n",
    "  \"Coral Sea Islands Territory\": \"Australia\",\n",
    "  \"People's Republic of China\": \"China\",\n",
    "  \"PRC\": \"China\",\n",
    "  \"Hong Kong S.A.R.\": \"China\",\n",
    "  \"Hong Kong\": \"China\",\n",
    "  \"Macao S.A.R\": \"China\",\n",
    "  \"Macau\": \"China\",\n",
    "  \"Czech Republic\": \"Czechia\",\n",
    "  \"Cape Verde\": \"Cabo Verde\",\n",
    "  \"Congo DRC\": \"Democratic Republic of the Congo\",\n",
    "  \"Democratic Republic of the Congo\": \"Democratic Republic of the Congo\",\n",
    "  \"Congo Republic\": \"Republic of the Congo\",\n",
    "  \"Eswatini\": \"eSwatini\",\n",
    "  \"Bahamas\": \"Bahamas\",\n",
    "  \"The Bahamas\": \"Bahamas\",\n",
    "  \"Gambia\": \"Gambia\",\n",
    "  \"The Gambia\": \"Gambia\",\n",
    "  \"Palestinian Authority\": \"Palestine\",\n",
    "  \"State of Palestine\": \"Palestine\",\n",
    "  \"Sixth Republic of South Korea\": \"South Korea\",\n",
    "  \"Republic of Serbia\": \"Serbia\",\n",
    "  \"Sao Tome and Principe\": \"São Tomé and Príncipe\",\n",
    "  \"Ivory Coast\": \"Ivory Coast\",\n",
    "  \"Côte d'Ivoire\": \"Ivory Coast\",\n",
    "  \"Fiji Islands\": \"Fiji\",\n",
    "  \"Portuguese Republic\": \"Portugal\",\n",
    "  \"Republic of Portugal\": \"Portugal\",\n",
    "  \"Republic of Poland\": \"Poland\",\n",
    "  \"Polish Republic\": \"Poland\",\n",
    "  \"United Republic of Tanzania\": \"Tanzania\",\n",
    "  \"Somaliland\": \"Somalia\",\n",
    "  \"East Timor\": \"Timor Leste\",\n",
    "  \"Timor-Leste\": \"Timor Leste\",\n",
    "  \"Jan Mayen\": \"Norway\",\n",
    "  \"Bouvet Island\": \"Norway\",\n",
    "  \"Svalbard\": \"Norway\",\n",
    "  \"Tristan da Cunha\": \"United Kingdom\",\n",
    "  \"Tokelau\": \"New Zealand\",\n",
    "  \"Cook Islands\": \"Cook Islands\",\n",
    "  \"American Samoa\": \"United States of America\",\n",
    "  \"Bouvet Island\": \"Norway\",\n",
    "  \"Cayman Islands\": \"United Kingdom\",\n",
    "  \"Cook Islands\": \"New Zealand\",\n",
    "  \"East Timor\": \"Timor Leste\",\n",
    "  \"French Southern Lands\": \"France\",\n",
    "  \"Guam\": \"United States of America\",\n",
    "  \"Jan Mayen\": \"Norway\",\n",
    "  \"Micronesia\": \"Federated States of Micronesia\",\n",
    "  \"Niue\": \"New Zealand\",\n",
    "  \"Norfolk Island\": \"Australia\",\n",
    "  \"Northern Marianas\": \"United States of America\",\n",
    "  \"Pitcairn Island\": \"United Kingdom\",\n",
    "  \"Puerto Rico\": \"United States of America\",\n",
    "  \"Saint Barthelemy\": \"France\",\n",
    "  \"Saint Helena, Ascension, Tristan da Cunha\": \"United Kingdom\",\n",
    "  \"Saint Martin\": \"France\",\n",
    "  \"Svalbard\": \"Norway\",\n",
    "  \"Tokelau\": \"New Zealand\",\n",
    "  \"U.S. Virgin Islands\": \"United States of America\",\n",
    "  \"Vatican City\": \"Vatican\",\n",
    "  \"Kingdom of Lesotho\": \"Lesotho\",\n",
    "  \"Heard Island and McDonald Islands\": \"Australia\"\n",
    "}\n",
    "\n",
    "with open(\"country_map.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(country_map, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, json\n",
    "\n",
    "caps = pd.read_json(\"caps_clean.json\")\n",
    "\n",
    "with open(\"country_map.json\") as f:\n",
    "    cmap = json.load(f)\n",
    "cmap.setdefault(\"Kosovo\", \"Kosovo\")\n",
    "with open(\"country_map.json\",\"w\") as f:\n",
    "    json.dump(cmap,f,indent=2)\n",
    "\n",
    "if \"Kosovo\" not in caps.country.values:\n",
    "    caps.loc[len(caps)] = {\n",
    "        \"country\":    \"Kosovo\",\n",
    "        \"capital\":    \"Pristina\",\n",
    "        \"lat_dd\":     42.6629,\n",
    "        \"lon_dd\":     21.1655,\n",
    "        \"description\":\"Capital of Kosovo\",\n",
    "        \"photo_url\":  None\n",
    "    }\n",
    "    caps.to_json(\"caps_clean.json\", orient=\"records\", indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 countries by distance:\n",
      "United Kingdom: 12255 km (Mount Paget→London)\n",
      "Netherlands: 6985 km (Mount Scenery→Amsterdam)\n",
      "Australia: 6036 km (Big Ben→Canberra)\n",
      "United States of America: 5439 km (Denali→Washington, D.C.)\n",
      "Canada: 4431 km (Mount Logan→Ottawa)\n",
      "\n",
      "Shortest distance:\n",
      "San Marino: 0 km (Monte Titano→San Marino)\n"
     ]
    }
   ],
   "source": [
    "top5 = (\n",
    "    dist\n",
    "    .nlargest(5, 'dist_km')\n",
    "    [['country', 'capital', 'peak', 'dist_km']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "min1 = (\n",
    "    dist\n",
    "    .nsmallest(1, 'dist_km')\n",
    "    [['country', 'capital', 'peak', 'dist_km']]\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "\n",
    "lines_top = [\n",
    "    f\"{row.country}: {row.dist_km:.0f} km ({row.peak}→{row.capital})\"\n",
    "    for row in top5.itertuples()\n",
    "]\n",
    "lines_min = [\n",
    "    f\"{row.country}: {row.dist_km:.0f} km ({row.peak}→{row.capital})\"\n",
    "    for row in min1.itertuples()\n",
    "]\n",
    "\n",
    "annotation = (\n",
    "    \"Top 5 countries by distance:\\n\" +\n",
    "    \"\\n\".join(lines_top) +\n",
    "    \"\\n\\nShortest distance:\\n\" +\n",
    "    \"\\n\".join(lines_min)\n",
    ")\n",
    "\n",
    "print(annotation)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_min=  10, γ=0.20, N=3 → [   10   958 10000]\n",
      "x_min=  10, γ=0.20, N=4 → [   10   315  2379 10000]\n",
      "x_min=  10, γ=0.20, N=5 → [   10   162   958  3547 10000]\n",
      "x_min=  10, γ=0.20, N=6 → [   10   104   507  1686  4443 10000]\n",
      "x_min=  10, γ=0.22, N=3 → [   10  1053 10000]\n",
      "x_min=  10, γ=0.22, N=4 → [   10   353  2538 10000]\n",
      "x_min=  10, γ=0.22, N=5 → [   10   182  1053  3724 10000]\n",
      "x_min=  10, γ=0.22, N=6 → [   10   116   564  1821  4620 10000]\n",
      "x_min=  10, γ=0.24, N=3 → [   10  1152 10000]\n",
      "x_min=  10, γ=0.24, N=4 → [   10   395  2698 10000]\n",
      "x_min=  10, γ=0.24, N=5 → [   10   204  1152  3898 10000]\n",
      "x_min=  10, γ=0.24, N=6 → [   10   130   626  1959  4791 10000]\n",
      "x_min=  10, γ=0.26, N=3 → [   10  1255 10000]\n",
      "x_min=  10, γ=0.26, N=4 → [   10   440  2857 10000]\n",
      "x_min=  10, γ=0.26, N=5 → [   10   229  1255  4068 10000]\n",
      "x_min=  10, γ=0.26, N=6 → [   10   145   693  2099  4956 10000]\n",
      "x_min=  10, γ=0.28, N=3 → [   10  1362 10000]\n",
      "x_min=  10, γ=0.28, N=4 → [   10   490  3015 10000]\n",
      "x_min=  10, γ=0.28, N=5 → [   10   256  1362  4234 10000]\n",
      "x_min=  10, γ=0.28, N=6 → [   10   163   764  2241  5116 10000]\n",
      "x_min=  10, γ=0.30, N=3 → [   10  1473 10000]\n",
      "x_min=  10, γ=0.30, N=4 → [   10   543  3172 10000]\n",
      "x_min=  10, γ=0.30, N=5 → [   10   286  1473  4396 10000]\n",
      "x_min=  10, γ=0.30, N=6 → [   10   182   839  2383  5270 10000]\n",
      "x_min=  50, γ=0.20, N=3 → [   50  1384 10000]\n",
      "x_min=  50, γ=0.20, N=4 → [   50   573  2928 10000]\n",
      "x_min=  50, γ=0.20, N=5 → [   50   345  1384  4099 10000]\n",
      "x_min=  50, γ=0.20, N=6 → [   50   248   830  2199  4965 10000]\n",
      "x_min=  50, γ=0.22, N=3 → [   50  1470 10000]\n",
      "x_min=  50, γ=0.22, N=4 → [   50   613  3059 10000]\n",
      "x_min=  50, γ=0.22, N=5 → [   50   369  1470  4239 10000]\n",
      "x_min=  50, γ=0.22, N=6 → [   50   264   888  2314  5101 10000]\n",
      "x_min=  50, γ=0.24, N=3 → [   50  1559 10000]\n",
      "x_min=  50, γ=0.24, N=4 → [   50   657  3189 10000]\n",
      "x_min=  50, γ=0.24, N=5 → [   50   394  1559  4376 10000]\n",
      "x_min=  50, γ=0.24, N=6 → [   50   281   949  2431  5234 10000]\n",
      "x_min=  50, γ=0.26, N=3 → [   50  1651 10000]\n",
      "x_min=  50, γ=0.26, N=4 → [   50   703  3320 10000]\n",
      "x_min=  50, γ=0.26, N=5 → [   50   422  1651  4511 10000]\n",
      "x_min=  50, γ=0.26, N=6 → [   50   300  1012  2549  5363 10000]\n",
      "x_min=  50, γ=0.28, N=3 → [   50  1746 10000]\n",
      "x_min=  50, γ=0.28, N=4 → [   50   752  3449 10000]\n",
      "x_min=  50, γ=0.28, N=5 → [   50   452  1746  4644 10000]\n",
      "x_min=  50, γ=0.28, N=6 → [   50   320  1079  2668  5488 10000]\n",
      "x_min=  50, γ=0.30, N=3 → [   50  1842 10000]\n",
      "x_min=  50, γ=0.30, N=4 → [   50   804  3578 10000]\n",
      "x_min=  50, γ=0.30, N=5 → [   50   484  1842  4773 10000]\n",
      "x_min=  50, γ=0.30, N=6 → [   50   342  1148  2787  5610 10000]\n",
      "x_min= 100, γ=0.20, N=3 → [  100  1669 10000]\n",
      "x_min= 100, γ=0.20, N=4 → [  100   769  3264 10000]\n",
      "x_min= 100, γ=0.20, N=5 → [  100   497  1669  4425 10000]\n",
      "x_min= 100, γ=0.20, N=6 → [  100   375  1064  2523  5266 10000]\n",
      "x_min= 100, γ=0.22, N=3 → [  100  1750 10000]\n",
      "x_min= 100, γ=0.22, N=4 → [  100   811  3380 10000]\n",
      "x_min= 100, γ=0.22, N=5 → [  100   522  1750  4546 10000]\n",
      "x_min= 100, γ=0.22, N=6 → [  100   392  1121  2627  5383 10000]\n",
      "x_min= 100, γ=0.24, N=3 → [  100  1834 10000]\n",
      "x_min= 100, γ=0.24, N=4 → [  100   854  3496 10000]\n",
      "x_min= 100, γ=0.24, N=5 → [  100   549  1834  4665 10000]\n",
      "x_min= 100, γ=0.24, N=6 → [  100   411  1179  2733  5497 10000]\n",
      "x_min= 100, γ=0.26, N=3 → [  100  1919 10000]\n",
      "x_min= 100, γ=0.26, N=4 → [  100   900  3611 10000]\n",
      "x_min= 100, γ=0.26, N=5 → [  100   578  1919  4783 10000]\n",
      "x_min= 100, γ=0.26, N=6 → [  100   431  1240  2839  5608 10000]\n",
      "x_min= 100, γ=0.28, N=3 → [  100  2006 10000]\n",
      "x_min= 100, γ=0.28, N=4 → [  100   948  3726 10000]\n",
      "x_min= 100, γ=0.28, N=5 → [  100   608  2006  4898 10000]\n",
      "x_min= 100, γ=0.28, N=6 → [  100   453  1304  2945  5717 10000]\n",
      "x_min= 100, γ=0.30, N=3 → [  100  2094 10000]\n",
      "x_min= 100, γ=0.30, N=4 → [  100   997  3840 10000]\n",
      "x_min= 100, γ=0.30, N=5 → [  100   640  2094  5011 10000]\n",
      "x_min= 100, γ=0.30, N=6 → [  100   475  1369  3052  5823 10000]\n",
      "x_min=1000, γ=0.20, N=3 → [ 1000  3606 10000]\n",
      "x_min=1000, γ=0.20, N=4 → [ 1000  2437  5188 10000]\n",
      "x_min=1000, γ=0.20, N=5 → [ 1000  1979  3606  6163 10000]\n",
      "x_min=1000, γ=0.20, N=6 → [ 1000  1739  2861  4500  6816 10000]\n",
      "x_min=1000, γ=0.22, N=3 → [ 1000  3653 10000]\n",
      "x_min=1000, γ=0.22, N=4 → [ 1000  2468  5241 10000]\n",
      "x_min=1000, γ=0.22, N=5 → [ 1000  2001  3653  6215 10000]\n",
      "x_min=1000, γ=0.22, N=6 → [ 1000  1756  2899  4552  6863 10000]\n",
      "x_min=1000, γ=0.24, N=3 → [ 1000  3700 10000]\n",
      "x_min=1000, γ=0.24, N=4 → [ 1000  2500  5295 10000]\n",
      "x_min=1000, γ=0.24, N=5 → [ 1000  2025  3700  6266 10000]\n",
      "x_min=1000, γ=0.24, N=6 → [ 1000  1774  2937  4605  6909 10000]\n",
      "x_min=1000, γ=0.26, N=3 → [ 1000  3748 10000]\n",
      "x_min=1000, γ=0.26, N=4 → [ 1000  2532  5349 10000]\n",
      "x_min=1000, γ=0.26, N=5 → [ 1000  2048  3748  6316 10000]\n",
      "x_min=1000, γ=0.26, N=6 → [ 1000  1793  2976  4657  6955 10000]\n",
      "x_min=1000, γ=0.28, N=3 → [ 1000  3795 10000]\n",
      "x_min=1000, γ=0.28, N=4 → [ 1000  2565  5402 10000]\n",
      "x_min=1000, γ=0.28, N=5 → [ 1000  2073  3795  6366 10000]\n",
      "x_min=1000, γ=0.28, N=6 → [ 1000  1812  3016  4710  7000 10000]\n",
      "x_min=1000, γ=0.30, N=3 → [ 1000  3843 10000]\n",
      "x_min=1000, γ=0.30, N=4 → [ 1000  2599  5454 10000]\n",
      "x_min=1000, γ=0.30, N=5 → [ 1000  2097  3843  6415 10000]\n",
      "x_min=1000, γ=0.30, N=6 → [ 1000  1831  3056  4762  7045 10000]\n"
     ]
    }
   ],
   "source": [
    "# make a grid search to find good tick values\n",
    "\n",
    "def generate_ticks(x_min, x_max, gamma, N):\n",
    "    y_min = x_min**gamma\n",
    "    y_max = x_max**gamma\n",
    "    y_ticks = np.linspace(y_min, y_max, N)\n",
    "    km_ticks = np.round(y_ticks**(1/gamma)).astype(int)\n",
    "    return km_ticks\n",
    "\n",
    "x_max = 10000\n",
    "x_min_list = [10, 50, 100, 1000]\n",
    "gamma_list = np.linspace(0.2, 0.3, 6)\n",
    "N_list = [3, 4, 5, 6]\n",
    "\n",
    "for x_min in x_min_list:\n",
    "    for gamma in gamma_list:\n",
    "        for N in N_list:\n",
    "            ticks = generate_ticks(x_min, x_max, gamma, N)\n",
    "            print(f\"x_min={x_min:>4}, γ={gamma:.2f}, N={N} → {ticks}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.models import ColumnDataSource, HoverTool, LinearColorMapper, ColorBar, FixedTicker, Div, CustomJS, Label\n",
    "from bokeh.layouts import column\n",
    "from bokeh.palettes import Blues256\n",
    "from bokeh.embed import components\n",
    "from bokeh.resources import CDN\n",
    "\n",
    "peak_style = {\"fill_color\":\"#002847\",\"line_color\":\"#002847\",\"line_width\":1}\n",
    "\n",
    "cap_style = {\"fill_color\":\"#7dbaff\",\"line_color\":\"#7dbaff\",\"line_width\":1}\n",
    "\n",
    "gamma = 0.26\n",
    "km_ticks = [10, 1000, 10000]\n",
    "palette = Blues256[::-1][15:]\n",
    "back_color, text_color = \"white\", \"gray\"\n",
    "show_peaks, show_caps = True, True\n",
    "\n",
    "with open(\"country_map.json\") as f:\n",
    "    cmap = json.load(f)\n",
    "unify = lambda n: cmap.get(n, n)\n",
    "\n",
    "peaks = pd.read_json(\"peaks_with_images.json\")\n",
    "caps = pd.read_json(\"caps_clean.json\")\n",
    "sub = gpd.read_file(\"ne_subunits/ne_10m_admin_0_map_subunits.shp\")\n",
    "\n",
    "peaks[\"country\"] = peaks[\"country\"].apply(unify)\n",
    "caps[\"country\"] = caps[\"country\"].apply(unify)\n",
    "sub = sub[sub.ADMIN!=\"Antarctica\"].assign(country=sub.ADMIN.apply(unify))\n",
    "\n",
    "peaks = peaks[peaks.lat_dd > -60]\n",
    "peaks = peaks.assign(country=peaks.country.str.split(\"/\")).explode(\"country\")\n",
    "peaks = peaks.loc[peaks.groupby(\"country\")[\"elev_m\"].idxmax()].reset_index(drop=True)\n",
    "\n",
    "def hav(a,b,c,d):\n",
    "    R=6371\n",
    "    la1,lo1,la2,lo2=np.radians([a,b,c,d])\n",
    "    dlat,dlon=la2-la1,lo2-lo1\n",
    "    h=np.sin(dlat/2)**2+np.cos(la1)*np.cos(la2)*np.sin(dlon/2)**2\n",
    "    return R*2*np.arctan2(np.sqrt(h),np.sqrt(1-h))\n",
    "\n",
    "dist = peaks.merge(caps,on=\"country\",suffixes=(\"_pk\",\"_cp\"))\n",
    "dist[\"dist_km\"] = hav(dist.lat_dd_pk,dist.lon_dd_pk,dist.lat_dd_cp,dist.lon_dd_cp)\n",
    "\n",
    "cn = sub.dissolve(by=\"country\").reset_index()\n",
    "cn = cn.merge(dist[[\"country\",\"dist_km\",\"peak\",\"capital\",\"elev_m\"]],on=\"country\",how=\"left\").explode(ignore_index=True)\n",
    "crs_proj = \"+proj=robin +lon_0=0 +datum=WGS84 +units=m +no_defs\"\n",
    "cn = cn.to_crs(crs_proj)\n",
    "cn[\"xs\"] = cn.geometry.apply(lambda p: list(p.exterior.coords.xy[0]))\n",
    "cn[\"ys\"] = cn.geometry.apply(lambda p: list(p.exterior.coords.xy[1]))\n",
    "cn = cn.drop(columns=[\"geometry\"])\n",
    "cn[\"alpha\"] = 1\n",
    "cn[\"dist_scaled\"] = cn[\"dist_km\"]**gamma\n",
    "\n",
    "peaks = gpd.GeoDataFrame(peaks,geometry=gpd.points_from_xy(peaks.lon_dd,peaks.lat_dd),crs=\"EPSG:4326\").to_crs(crs_proj)\n",
    "peaks[\"x\"],peaks[\"y\"]=peaks.geometry.x,peaks.geometry.y\n",
    "peaks=peaks.drop(columns=\"geometry\");peaks[\"alpha\"]=1\n",
    "\n",
    "caps = gpd.GeoDataFrame(caps,geometry=gpd.points_from_xy(caps.lon_dd,caps.lat_dd),crs=\"EPSG:4326\").to_crs(crs_proj)\n",
    "caps[\"x\"],caps[\"y\"]=caps.geometry.x,caps.geometry.y\n",
    "caps=caps.drop(columns=\"geometry\");caps[\"alpha\"]=1\n",
    "\n",
    "gsrc = ColumnDataSource(cn)\n",
    "peaks_src = ColumnDataSource(peaks)\n",
    "caps_src = ColumnDataSource(caps)\n",
    "\n",
    "mapper = LinearColorMapper(palette=palette, low=cn[\"dist_scaled\"].min(), high=cn[\"dist_scaled\"].max())\n",
    "\n",
    "xs = np.hstack(cn[\"xs\"].to_list()); ys = np.hstack(cn[\"ys\"].to_list())\n",
    "pad_x = -0.001*(xs.max()-xs.min()); pad_y = 0.001*(ys.max()-ys.min())\n",
    "x0,x1 = xs.min()+pad_x, xs.max()-pad_x; y0,y1 = ys.min()+pad_y, ys.max()-pad_y\n",
    "base_width = 800; ratio=(x1-x0)/(y1-y0); base_height=int(base_width/ratio)\n",
    "\n",
    "p = figure(x_range=(x0,x1),y_range=(y0,y1),width=base_width,height=base_height,\n",
    "           sizing_mode=\"stretch_both\",tools=\"pan,wheel_zoom,reset,tap\",\n",
    "           active_scroll=\"wheel_zoom\",toolbar_location=None,\n",
    "           background_fill_color=back_color,border_fill_color=back_color,min_border=0)\n",
    "p.name=\"map_plot\"; p.axis.visible=False; p.grid.grid_line_color=None\n",
    "p.title.text=\"Distance from Capital to Highest Peak — by Sovereign State\"; p.title.align=\"center\"\n",
    "p.title.text_font_size=\"40pt\"; p.title.text_color=\"gray\"; p.min_border_top=50\n",
    "\n",
    "p.patches(\"xs\",\"ys\",source=gsrc,\n",
    "          fill_color={\"field\":\"dist_scaled\",\"transform\":mapper},\n",
    "          line_color=None,fill_alpha=\"alpha\",line_alpha=\"alpha\")\n",
    "\n",
    "if show_peaks:\n",
    "    p.scatter(\"x\",\"y\",source=peaks_src,marker=\"triangle\",size=7,\n",
    "              fill_color=peak_style[\"fill_color\"], line_color=peak_style[\"line_color\"],\n",
    "              line_width=peak_style[\"line_width\"], fill_alpha=\"alpha\", line_alpha=\"alpha\",\n",
    "              legend_label=\"Highest peak\")\n",
    "if show_caps:\n",
    "    p.scatter(\"x\",\"y\",source=caps_src,marker=\"star\",size=7,\n",
    "              fill_color=cap_style[\"fill_color\"], line_color=cap_style[\"line_color\"],\n",
    "              line_width=cap_style[\"line_width\"], fill_alpha=\"alpha\", line_alpha=\"alpha\",\n",
    "              legend_label=\"Capital city\")\n",
    "\n",
    "tooltip=\"\"\"\n",
    "<div style=\"background:rgba(34,34,34,0.8);color:#eee;padding:6px;border-radius:8px\">\n",
    "  <b>@country</b> — @capital / @peak<br>\n",
    "  Elev: @elev_m m, Dist: @dist_km{0.0} km\n",
    "</div>\n",
    "\"\"\"\n",
    "p.add_tools(HoverTool(renderers=[p.renderers[0]], tooltips=tooltip, point_policy=\"follow_mouse\", show_arrow=False))\n",
    "\n",
    "p.legend.location=(10,50); p.legend.background_fill_alpha=0\n",
    "p.legend.label_text_color=text_color; p.legend.label_text_font_size=\"10pt\"; p.legend.border_line_color=None\n",
    "\n",
    "scaled_ticks = [t**gamma for t in km_ticks]\n",
    "color_bar = ColorBar(color_mapper=mapper, ticker=FixedTicker(ticks=scaled_ticks),\n",
    "                     major_label_overrides={st:f\"{km} km\" for st,km in zip(scaled_ticks,km_ticks)},\n",
    "                     orientation=\"horizontal\", background_fill_alpha=0, border_line_alpha=0,\n",
    "                     width=200, height=10, location=(0,2))\n",
    "p.add_layout(color_bar)\n",
    "\n",
    "label = Label(x=0,y=0,x_units=\"data\",y_units=\"data\",text=\"\",text_font_size=\"10pt\",text_color=\"#eee\",\n",
    "              background_fill_color=\"rgba(34,34,34,0.8)\",background_fill_alpha=1,\n",
    "              border_line_color=None,padding=4,border_radius=8)\n",
    "p.add_layout(label)\n",
    "\n",
    "callback = CustomJS(args=dict(src=gsrc,peaks_src=peaks_src,caps_src=caps_src,lab=label), code=\"\"\"\n",
    "var data=src.data,pd=peaks_src.data,cd=caps_src.data,inds=src.selected.indices;\n",
    "if(inds.length==0){\n",
    "  for(var i=0;i<data.alpha.length;i++){\n",
    "    data.alpha[i]=pd.alpha[i]=cd.alpha[i]=1;\n",
    "  }\n",
    "  lab.text=\"\";src.change.emit();peaks_src.change.emit();caps_src.change.emit();return;\n",
    "}\n",
    "var country=data.country[inds[0]],new_sel=[];\n",
    "for(var i=0;i<data.country.length;i++){\n",
    "  if(data.country[i]===country){new_sel.push(i);data.alpha[i]=1;}else{data.alpha[i]=0.2;}\n",
    "}\n",
    "for(var i=0;i<pd.country.length;i++){\n",
    "  pd.alpha[i]=pd.country[i]===country?1:0.2;\n",
    "  cd.alpha[i]=cd.country[i]===country?1:0.2;\n",
    "}\n",
    "src.selected.indices=new_sel;\n",
    "var cap_i=cd.country.indexOf(country);\n",
    "lab.x=cd.x[cap_i];lab.y=cd.y[cap_i];\n",
    "lab.text=country+\" — \"+data.capital[inds[0]]+\" / \"+data.peak[inds[0]]\n",
    "  +\"\\\\nElev: \"+data.elev_m[inds[0]]+\" m, Dist: \"+data.dist_km[inds[0]].toFixed(1)+\" km\";\n",
    "src.change.emit();peaks_src.change.emit();caps_src.change.emit();\n",
    "\"\"\")\n",
    "gsrc.selected.js_on_change(\"indices\", callback)\n",
    "\n",
    "credit_div = Div(text=\"\"\"\n",
    "<div style='text-align:right; font-size:10pt; color:#555; width:100%;'>\n",
    "  Data: <a href='https://www.peakbagger.com'>Peakbagger</a> |\n",
    "  <a href='https://www.wikipedia.org'>Wikipedia</a> |\n",
    "  <a href='https://www.naturalearthdata.com'>Natural Earth</a> ―\n",
    "  Plotting: <a href='https://bokeh.org'>Bokeh</a> ―\n",
    "  Code: <a href='https://github.com/jan-mate/peak_capital_distance'>GitHub</a>\n",
    "</div>\n",
    "\"\"\", sizing_mode=\"stretch_width\", margin=(0,0,0,0))\n",
    "\n",
    "layout = column(p, credit_div, sizing_mode=\"stretch_both\")\n",
    "script, div = components(layout)\n",
    "cdn_js, cdn_css = CDN.js_files, CDN.css_files\n",
    "js = \"\".join(f'<script src=\"{u}\"></script>' for u in cdn_js)\n",
    "css = \"\".join(f'<link href=\"{u}\" rel=\"stylesheet\">' for u in cdn_css)\n",
    "\n",
    "html = f\"\"\"\n",
    "<html>\n",
    "<head>\n",
    "  {css}{js}\n",
    "  <style>\n",
    "    html, body {{margin:0;padding:0;height:100%;overflow:hidden;}}\n",
    "    #map-container {{width:100%;height:100%;}}\n",
    "    .bk-tooltip{{background-color:transparent!important;border:none!important;box-shadow:none!important;}}\n",
    "    .bk-tooltip>div{{background:rgba(34,34,34,0.8)!important;color:#eee!important;padding:6px!important;border-radius:8px!important;}}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <div id=\"map-container\">{div}</div>{script}\n",
    "  <script>\n",
    "    function updateZoom(){{const doc=Bokeh.documents[0],plot=doc.get_model_by_name(\"map_plot\"),c=document.getElementById(\"map-container\"),w=c.clientWidth,h=c.clientHeight,dataRatio=(plot.x_range.end-plot.x_range.start)/(plot.y_range.end-plot.y_range.start),contRatio=w/h;if(contRatio>dataRatio){{const halfW=(plot.y_range.end-plot.y_range.start)*contRatio/2,mid=(plot.x_range.start+plot.x_range.end)/2;plot.x_range.start=mid-halfW;plot.x_range.end=mid+halfW;}}else{{const halfH=(plot.x_range.end-plot.x_range.start)/contRatio/2,mid=(plot.y_range.start+plot.y_range.end)/2;plot.y_range.start=mid-halfH;plot.y_range.end=mid+halfH;}}}}\n",
    "    function initZoom(){{if(!window.Bokeh||Bokeh.documents.length===0){{setTimeout(initZoom,50);}}else{{updateZoom();}}}}\n",
    "    window.addEventListener(\"load\",initZoom);window.addEventListener(\"resize\",updateZoom);\n",
    "  </script>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "with open(\"peak_capital_distance.html\",\"w\") as f:\n",
    "    f.write(html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
